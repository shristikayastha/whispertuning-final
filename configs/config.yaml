# Nepali ASR Configuration


# Model Configuration
model:
  name: "openai/whisper-small"
  language: "ne"  # Nepali
  task: "transcribe"
  
# LoRA Configuration
lora:
  r: 32                    # LoRA rank
  lora_alpha: 64           # Scaling factor
  lora_dropout: 0.1
  target_modules:
    - "q_proj"
    - "v_proj"
    - "k_proj"
    - "out_proj"
  bias: "none"

# Data Configuration
data:
  dataset_name: "mozilla-foundation/common_voice_13_0"
  language: "ne-NP"
  train_split: "train"
  validation_split: "validation"
  test_split: "test"
  max_audio_length: 30.0   # seconds
  sampling_rate: 16000

# Training Configuration
training:
  output_dir: "./outputs/checkpoints"
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 2
  learning_rate: 1.0e-4
  warmup_steps: 500
  max_steps: 5000
  fp16: true
  evaluation_strategy: "steps"
  eval_steps: 500
  save_steps: 500
  logging_steps: 25
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: "wer"
  greater_is_better: false
  predict_with_generate: true
  generation_max_length: 225

# Inference Configuration
inference:
  model_path: "./outputs/checkpoints/best_model"
  device: "cuda"  # or "cpu"
  batch_size: 1

# Demo Configuration
demo:
  title: "ðŸ‡³ðŸ‡µ Nepali Speech Recognition"
  description: "Fine-tuned Whisper model for Nepali ASR"
  theme: "soft"
  share: false
